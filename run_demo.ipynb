{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ§  Atlas â€” Interactive Demo\n",
                "\n",
                "Welcome! This notebook walks you through the Atlas long-form memory system step by step.\n",
                "\n",
                "**What you'll learn:**\n",
                "1. How the agent extracts memories from conversation\n",
                "2. How memories are stored and retrieved\n",
                "3. How to test memory recall\n",
                "4. How to use different providers (Ollama, Gemini, Groq)\n",
                "\n",
                "> ğŸ“Š For full benchmarks and evaluation results, see **[results.ipynb](results.ipynb)**\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup\n",
                "\n",
                "First, install dependencies and load the environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/pik/dev/atlas/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ“ Dependencies loaded\n",
                        "  Project root: /home/pik/dev/atlas\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "import json\n",
                "from pathlib import Path\n",
                "\n",
                "# Add project root to path\n",
                "project_root = Path.cwd()\n",
                "if str(project_root) not in sys.path:\n",
                "    sys.path.insert(0, str(project_root))\n",
                "\n",
                "from src.agent import LongMemAgent\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "print('âœ“ Dependencies loaded')\n",
                "print(f'  Project root: {project_root}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Choose Your Provider\n",
                "\n",
                "Atlas supports multiple LLM backends. Pick one:\n",
                "\n",
                "| Provider | Model | API Key Needed | Notes |\n",
                "|----------|-------|:--------------:|-------|\n",
                "| `ollama` | `mistral` | No | Local, fast, free. Run `ollama serve` first |\n",
                "| `gemini` | `gemma-3-27b-it` | `GEMINI_API_KEY` | Free tier, 30 req/min |\n",
                "| `groq` | `llama-3.1-8b-instant` | `GROQ_API_KEY` | Very fast, rate limited |\n",
                "\n",
                "Edit the cell below to change providers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ—‘ï¸  Cleaned previous demo_interactive.db\n",
                        "\n",
                        "âœ“ Agent initialized\n",
                        "  Provider: groq\n",
                        "  Model:    moonshotai/kimi-k2-instruct-0905\n",
                        "  DB:       demo_interactive.db\n"
                    ]
                }
            ],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# ğŸ”§ CONFIGURE YOUR PROVIDER HERE\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\n",
                "PROVIDER = 'groq'                 # 'ollama', 'gemini', or 'groq'\n",
                "# MODEL    = 'mistral'                # model name for your provider\n",
                "# MODEL  = 'gemma-3-27b-it'         # uncomment for Gemini\n",
                "MODEL  = 'moonshotai/kimi-k2-instruct-0905'   # uncomment for Groq\n",
                "\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\n",
                "# Clean up any previous demo database\n",
                "demo_db = 'demo_interactive.db'\n",
                "if os.path.exists(demo_db):\n",
                "    os.remove(demo_db)\n",
                "    print(f'ğŸ—‘ï¸  Cleaned previous {demo_db}')\n",
                "\n",
                "# Initialize agent\n",
                "agent = LongMemAgent(\n",
                "    provider=PROVIDER,\n",
                "    model=MODEL,\n",
                "    db_path=demo_db,\n",
                "    context_limit=4096,\n",
                "    flush_threshold=0.70\n",
                ")\n",
                "\n",
                "print(f'\\nâœ“ Agent initialized')\n",
                "print(f'  Provider: {agent.provider}')\n",
                "print(f'  Model:    {agent.model}')\n",
                "print(f'  DB:       {demo_db}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Chat Helper\n",
                "\n",
                "A nice helper to display conversations with memory metadata."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ“ Chat helper ready. Use chat(\"your message\") below!\n"
                    ]
                }
            ],
            "source": [
                "from IPython.display import display, Markdown, HTML\n",
                "\n",
                "def chat(message: str, show_memories=True):\n",
                "    \"\"\"Send a message and display the response with memory info.\"\"\"\n",
                "    print(f'\\n You: {message}')\n",
                "    \n",
                "    response = agent.chat(message)\n",
                "    \n",
                "    print(f'Atlas: {response[\"response\"]}')\n",
                "    print(f'\\n   â”Œâ”€ Turn {response[\"turn_id\"]} â”‚ '\n",
                "          f'Context: {response[\"context_utilization\"]} â”‚ '\n",
                "          f'Memories: {response[\"total_memories\"]} â”‚ '\n",
                "          f'Flush: {\"yes\" if response[\"flush_triggered\"] else \"no\"}')\n",
                "    \n",
                "    if show_memories and response['active_memories']:\n",
                "        print(f'   â”‚ ğŸ§  Retrieved {len(response[\"active_memories\"])} memories:')\n",
                "        for mem in response['active_memories']:\n",
                "            print(f'   â”‚   â€¢ {mem[\"content\"]} '\n",
                "                  f'(from turn {mem[\"origin_turn\"]}, conf: {mem[\"confidence\"]:.2f})')\n",
                "    print('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')\n",
                "    \n",
                "    \n",
                "    return response\n",
                "\n",
                "print('âœ“ Chat helper ready. Use chat(\"your message\") below!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Plant Some Memories\n",
                "\n",
                "Let's tell the agent some facts about ourselves. These will be extracted as memories."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        " You: Hi! My name is Jordan and I work as a data scientist in Seattle.\n",
                        "Atlas: Hey Jordan! Great to meet you. How's the data science scene treating you in Seattle?\n",
                        "\n",
                        "   â”Œâ”€ Turn 1 â”‚ Context: 3% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                        "\n",
                        " You: I'm allergic to peanuts and I follow a vegetarian diet.\n",
                        "Atlas: Got itâ€”peanuts off the table and vegetarian fare only. Need any dining tips in Seattle, or is there something else on your mind?\n",
                        "\n",
                        "   â”Œâ”€ Turn 2 â”‚ Context: 4% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                        "\n",
                        " You: My favorite programming language is Python. I also use R for statistics.\n",
                        "Atlas: Nice stackâ€”Python for the heavy lifting and R when you need those crisp statistical summaries. Working on anything right now thatâ€™s making you switch back and forth between them?\n",
                        "\n",
                        "   â”Œâ”€ Turn 3 â”‚ Context: 6% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                        "\n",
                        " You: I have a daughter named Maya, she is 5 years old.\n",
                        "Atlas: Thatâ€™s awesomeâ€”5 is such a fun age. Is Maya already showing any signs of future data-scientist curiosity, or is she more into dinosaurs and finger-painting these days?\n",
                        "\n",
                        "   â”Œâ”€ Turn 4 â”‚ Context: 7% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'Thatâ€™s awesomeâ€”5 is such a fun age. Is Maya already showing any signs of future data-scientist curiosity, or is she more into dinosaurs and finger-painting these days?',\n",
                            " 'turn_id': 4,\n",
                            " 'context_utilization': '7%',\n",
                            " 'context_tokens': 300,\n",
                            " 'retrieval_ms': 0.1,\n",
                            " 'total_ms': 614.4,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 0,\n",
                            " 'active_memories': [],\n",
                            " 'total_memories': 0}"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "chat('Hi! My name is Jordan and I work as a data scientist in Seattle.')\n",
                "chat(\"I'm allergic to peanuts and I follow a vegetarian diet.\")\n",
                "chat('My favorite programming language is Python. I also use R for statistics.')\n",
                "chat('I have a daughter named Maya, she is 5 years old.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Trigger Memory Distillation\n",
                "\n",
                "The agent normally distills memories when context hits 70% capacity.\n",
                "We can also trigger it manually to extract memories right now."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âš¡ Triggering memory distillation...\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 483.11it/s, Materializing param=pooler.dense.weight]                             \n",
                        "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
                        "Key                     | Status     |  | \n",
                        "------------------------+------------+--+-\n",
                        "embeddings.position_ids | UNEXPECTED |  | \n",
                        "\n",
                        "\u001b[3mNotes:\n",
                        "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[Store] Embedding model loaded on device: cuda:0\n",
                        "âœ“ Distillation complete. 8 memories extracted.\n",
                        "  Memories added: 8\n",
                        "  Total memories: 8\n"
                    ]
                }
            ],
            "source": [
                "print('âš¡ Triggering memory distillation...\\n')\n",
                "\n",
                "result = agent.manual_distill()\n",
                "\n",
                "print(f'âœ“ {result[\"message\"]}')\n",
                "print(f'  Memories added: {result[\"memories_added\"]}')\n",
                "print(f'  Total memories: {result[\"total_memories\"]}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Inspect Stored Memories\n",
                "\n",
                "Let's see what the distiller extracted."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ“¦ Stored Memories (8 total):\n",
                        "\n",
                        "  [        fact] user_name: Jordan\n",
                        "               confidence: 0.95, from turn 4\n",
                        "  [        fact] occupation: data scientist\n",
                        "               confidence: 0.95, from turn 4\n",
                        "  [        fact] location: Seattle\n",
                        "               confidence: 0.95, from turn 4\n",
                        "  [  constraint] allergy_peanuts: allergic to peanuts\n",
                        "               confidence: 0.95, from turn 4\n",
                        "  [  preference] dietary_preference: vegetarian\n",
                        "               confidence: 0.95, from turn 4\n",
                        "  [  preference] favorite_language: Python\n",
                        "               confidence: 0.95, from turn 4\n",
                        "  [        fact] uses_r: uses R for statistics\n",
                        "               confidence: 0.95, from turn 4\n",
                        "  [      entity] daughter_maya: daughter Maya, 5 years old\n",
                        "               confidence: 0.95, from turn 4\n"
                    ]
                }
            ],
            "source": [
                "memories = agent.get_all_memories()\n",
                "\n",
                "if memories:\n",
                "    print(f'ğŸ“¦ Stored Memories ({len(memories)} total):\\n')\n",
                "    for m in memories:\n",
                "        print(f\"  [{m['type']:>12}] {m['key']}: {m['value']}\")\n",
                "        print(f\"               confidence: {m['confidence']:.2f}, from turn {m['source_turn']}\")\n",
                "else:\n",
                "    print('No memories stored yet. Run distillation first.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Test Memory Recall\n",
                "\n",
                "Now the key test â€” does the agent remember what we told it?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        " You: What's my name?\n",
                        "Atlas: Jordan\n",
                        "\n",
                        "   â”Œâ”€ Turn 5 â”‚ Context: 7% â”‚ Memories: 8 â”‚ Flush: no\n",
                        "   â”‚ ğŸ§  Retrieved 2 memories:\n",
                        "   â”‚   â€¢ user_name: Jordan (from turn 4, conf: 0.95)\n",
                        "   â”‚   â€¢ daughter_maya: daughter Maya, 5 years old (from turn 4, conf: 0.95)\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'Jordan',\n",
                            " 'turn_id': 5,\n",
                            " 'context_utilization': '7%',\n",
                            " 'context_tokens': 293,\n",
                            " 'retrieval_ms': 10.7,\n",
                            " 'total_ms': 1045.3,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 1,\n",
                            " 'active_memories': [{'memory_id': 'mem_5afb288d',\n",
                            "   'content': 'user_name: Jordan',\n",
                            "   'origin_turn': 4,\n",
                            "   'last_used_turn': 5,\n",
                            "   'type': 'fact',\n",
                            "   'confidence': 0.95},\n",
                            "  {'memory_id': 'mem_ed2ba238',\n",
                            "   'content': 'daughter_maya: daughter Maya, 5 years old',\n",
                            "   'origin_turn': 4,\n",
                            "   'last_used_turn': 5,\n",
                            "   'type': 'entity',\n",
                            "   'confidence': 0.95}],\n",
                            " 'total_memories': 8}"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "chat(\"What's my name?\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        " You: Suggest a dinner recipe for me.\n",
                        "Atlas: Quick one-pan coconut chickpea spinach curryâ€”ready in 20 min, totally vegetarian, no peanuts anywhere.\n",
                        "\n",
                        "1. SautÃ© 1 diced onion + 2 cloves garlic in a splash of oil.  \n",
                        "2. Stir in 1 Tbsp mild curry powder, 1 tsp garam masala, Â¼ tsp chili flakes (optional).  \n",
                        "3. Add 1 can chickpeas (rinsed), 1 can full-fat coconut milk, 1 cup veggie broth; simmer 8 min.  \n",
                        "4. Fold in 3 big handfuls baby spinach until wilted; finish with juice of Â½ lime and salt to taste.  \n",
                        "5. Serve over rice or quinoa; top with cilantro and a drizzle of yogurt if Maya likes it creamy.\n",
                        "\n",
                        "Mild, sweet, and brightâ€”perfect for a five-year-old palate.\n",
                        "\n",
                        "   â”Œâ”€ Turn 6 â”‚ Context: 12% â”‚ Memories: 8 â”‚ Flush: no\n",
                        "   â”‚ ğŸ§  Retrieved 2 memories:\n",
                        "   â”‚   â€¢ dietary_preference: vegetarian (from turn 4, conf: 0.95)\n",
                        "   â”‚   â€¢ daughter_maya: daughter Maya, 5 years old (from turn 4, conf: 0.95)\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'Quick one-pan coconut chickpea spinach curryâ€”ready in 20 min, totally vegetarian, no peanuts anywhere.\\n\\n1. SautÃ© 1 diced onion + 2 cloves garlic in a splash of oil.  \\n2. Stir in 1 Tbsp mild curry powder, 1 tsp garam masala, Â¼ tsp chili flakes (optional).  \\n3. Add 1 can chickpeas (rinsed), 1 can full-fat coconut milk, 1 cup veggie broth; simmer 8 min.  \\n4. Fold in 3 big handfuls baby spinach until wilted; finish with juice of Â½ lime and salt to taste.  \\n5. Serve over rice or quinoa; top with cilantro and a drizzle of yogurt if Maya likes it creamy.\\n\\nMild, sweet, and brightâ€”perfect for a five-year-old palate.',\n",
                            " 'turn_id': 6,\n",
                            " 'context_utilization': '12%',\n",
                            " 'context_tokens': 486,\n",
                            " 'retrieval_ms': 24.6,\n",
                            " 'total_ms': 1207.8,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 1,\n",
                            " 'active_memories': [{'memory_id': 'mem_97d4e5a3',\n",
                            "   'content': 'dietary_preference: vegetarian',\n",
                            "   'origin_turn': 4,\n",
                            "   'last_used_turn': 6,\n",
                            "   'type': 'preference',\n",
                            "   'confidence': 0.95},\n",
                            "  {'memory_id': 'mem_ed2ba238',\n",
                            "   'content': 'daughter_maya: daughter Maya, 5 years old',\n",
                            "   'origin_turn': 4,\n",
                            "   'last_used_turn': 6,\n",
                            "   'type': 'entity',\n",
                            "   'confidence': 0.95}],\n",
                            " 'total_memories': 8}"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "chat('Suggest a dinner recipe for me.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        " You: What should I get my kid for her birthday?\n",
                        "Atlas: A build-your-own fairy-garden kit hits the sweet spot for a five-year-old: tiny wooden toadstools, felt flowers, a battery tea-light \"firefly\" jar, and a little watering can she can use for real plants. Itâ€™s hands-on, sparks imagination, and gives you two a weekend project together.\n",
                        "\n",
                        "   â”Œâ”€ Turn 7 â”‚ Context: 14% â”‚ Memories: 8 â”‚ Flush: no\n",
                        "   â”‚ ğŸ§  Retrieved 2 memories:\n",
                        "   â”‚   â€¢ daughter_maya: daughter Maya, 5 years old (from turn 4, conf: 0.95)\n",
                        "   â”‚   â€¢ favorite_language: Python (from turn 4, conf: 0.95)\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'A build-your-own fairy-garden kit hits the sweet spot for a five-year-old: tiny wooden toadstools, felt flowers, a battery tea-light \"firefly\" jar, and a little watering can she can use for real plants. Itâ€™s hands-on, sparks imagination, and gives you two a weekend project together.',\n",
                            " 'turn_id': 7,\n",
                            " 'context_utilization': '14%',\n",
                            " 'context_tokens': 572,\n",
                            " 'retrieval_ms': 13.6,\n",
                            " 'total_ms': 1007.6,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 1,\n",
                            " 'active_memories': [{'memory_id': 'mem_ed2ba238',\n",
                            "   'content': 'daughter_maya: daughter Maya, 5 years old',\n",
                            "   'origin_turn': 4,\n",
                            "   'last_used_turn': 7,\n",
                            "   'type': 'entity',\n",
                            "   'confidence': 0.95},\n",
                            "  {'memory_id': 'mem_3f5d864a',\n",
                            "   'content': 'favorite_language: Python',\n",
                            "   'origin_turn': 4,\n",
                            "   'last_used_turn': 7,\n",
                            "   'type': 'preference',\n",
                            "   'confidence': 0.95}],\n",
                            " 'total_memories': 8}"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "chat('What should I get my kid for her birthday?')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        " You: Tell me everything you remember about me.\n",
                        "Atlas: Youâ€™re Jordan, a data scientist in Seattle who codes in Python and dips into R for stats. Youâ€™re vegetarian, allergic to peanuts, and dad to 5-year-old Maya.\n",
                        "\n",
                        "   â”Œâ”€ Turn 8 â”‚ Context: 15% â”‚ Memories: 8 â”‚ Flush: no\n",
                        "   â”‚ ğŸ§  Retrieved 2 memories:\n",
                        "   â”‚   â€¢ user_name: Jordan (from turn 4, conf: 0.95)\n",
                        "   â”‚   â€¢ daughter_maya: daughter Maya, 5 years old (from turn 4, conf: 0.95)\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'Youâ€™re Jordan, a data scientist in Seattle who codes in Python and dips into R for stats. Youâ€™re vegetarian, allergic to peanuts, and dad to 5-year-old Maya.',\n",
                            " 'turn_id': 8,\n",
                            " 'context_utilization': '15%',\n",
                            " 'context_tokens': 625,\n",
                            " 'retrieval_ms': 13.2,\n",
                            " 'total_ms': 806.1,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 1,\n",
                            " 'active_memories': [{'memory_id': 'mem_5afb288d',\n",
                            "   'content': 'user_name: Jordan',\n",
                            "   'origin_turn': 4,\n",
                            "   'last_used_turn': 8,\n",
                            "   'type': 'fact',\n",
                            "   'confidence': 0.95},\n",
                            "  {'memory_id': 'mem_ed2ba238',\n",
                            "   'content': 'daughter_maya: daughter Maya, 5 years old',\n",
                            "   'origin_turn': 4,\n",
                            "   'last_used_turn': 8,\n",
                            "   'type': 'entity',\n",
                            "   'confidence': 0.95}],\n",
                            " 'total_memories': 8}"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "chat('Tell me everything you remember about me.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Try It Yourself!\n",
                "\n",
                "Use the cell below to have your own conversation with the agent.\n",
                "Each message is processed through the full memory pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        " You: What do I do for work?\n",
                        "Atlas: Youâ€™re a data scientist.\n",
                        "\n",
                        "   â”Œâ”€ Turn 9 â”‚ Context: 15% â”‚ Memories: 8 â”‚ Flush: no\n",
                        "   â”‚ ğŸ§  Retrieved 2 memories:\n",
                        "   â”‚   â€¢ occupation: data scientist (from turn 4, conf: 0.95)\n",
                        "   â”‚   â€¢ location: Seattle (from turn 4, conf: 0.95)\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'Youâ€™re a data scientist.',\n",
                            " 'turn_id': 9,\n",
                            " 'context_utilization': '15%',\n",
                            " 'context_tokens': 626,\n",
                            " 'retrieval_ms': 13.5,\n",
                            " 'total_ms': 602.5,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 1,\n",
                            " 'active_memories': [{'memory_id': 'mem_2f7ec706',\n",
                            "   'content': 'occupation: data scientist',\n",
                            "   'origin_turn': 4,\n",
                            "   'last_used_turn': 9,\n",
                            "   'type': 'fact',\n",
                            "   'confidence': 0.95},\n",
                            "  {'memory_id': 'mem_9e249652',\n",
                            "   'content': 'location: Seattle',\n",
                            "   'origin_turn': 4,\n",
                            "   'last_used_turn': 9,\n",
                            "   'type': 'fact',\n",
                            "   'confidence': 0.95}],\n",
                            " 'total_memories': 8}"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Type your message here:\n",
                "chat('What do I do for work?')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        " You: Your message here\n",
                        "Atlas: Got itâ€”thanks for the heads-up.\n",
                        "\n",
                        "   â”Œâ”€ Turn 10 â”‚ Context: 16% â”‚ Memories: 8 â”‚ Flush: no\n",
                        "   â”‚ ğŸ§  Retrieved 2 memories:\n",
                        "   â”‚   â€¢ user_name: Jordan (from turn 4, conf: 0.95)\n",
                        "   â”‚   â€¢ location: Seattle (from turn 4, conf: 0.95)\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'Got itâ€”thanks for the heads-up.',\n",
                            " 'turn_id': 10,\n",
                            " 'context_utilization': '16%',\n",
                            " 'context_tokens': 646,\n",
                            " 'retrieval_ms': 14.5,\n",
                            " 'total_ms': 594.7,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 1,\n",
                            " 'active_memories': [{'memory_id': 'mem_5afb288d',\n",
                            "   'content': 'user_name: Jordan',\n",
                            "   'origin_turn': 4,\n",
                            "   'last_used_turn': 10,\n",
                            "   'type': 'fact',\n",
                            "   'confidence': 0.95},\n",
                            "  {'memory_id': 'mem_9e249652',\n",
                            "   'content': 'location: Seattle',\n",
                            "   'origin_turn': 4,\n",
                            "   'last_used_turn': 10,\n",
                            "   'type': 'fact',\n",
                            "   'confidence': 0.95}],\n",
                            " 'total_memories': 8}"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Try another:\n",
                "chat('Your message here')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Database Peek\n",
                "\n",
                "Under the hood, memories are stored in SQLite with vector embeddings + full-text search indexes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ“‹ Database: demo_interactive.db\n",
                        "   Active memories: 8\n",
                        "   Total turns: 10\n",
                        "   Memory types:\n",
                        "     constraint: 1\n",
                        "     entity: 1\n",
                        "     fact: 4\n",
                        "     preference: 2\n"
                    ]
                }
            ],
            "source": [
                "import sqlite3\n",
                "\n",
                "conn = sqlite3.connect(demo_db)\n",
                "cursor = conn.cursor()\n",
                "\n",
                "cursor.execute('SELECT COUNT(*) FROM memories WHERE is_active = 1')\n",
                "active = cursor.fetchone()[0]\n",
                "\n",
                "cursor.execute('SELECT COUNT(*) FROM turns')\n",
                "turns = cursor.fetchone()[0]\n",
                "\n",
                "cursor.execute('''\n",
                "    SELECT type, COUNT(*) as count \n",
                "    FROM memories WHERE is_active = 1 \n",
                "    GROUP BY type\n",
                "''')\n",
                "types = cursor.fetchall()\n",
                "\n",
                "print(f'ğŸ“‹ Database: {demo_db}')\n",
                "print(f'   Active memories: {active}')\n",
                "print(f'   Total turns: {turns}')\n",
                "print(f'   Memory types:')\n",
                "for type_name, count in types:\n",
                "    print(f'     {type_name}: {count}')\n",
                "\n",
                "conn.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Next Steps\n",
                "\n",
                "| What | How |\n",
                "|:-----|:----|\n",
                "| ğŸ“Š **See benchmarks** | Open [results.ipynb](results.ipynb) |\n",
                "| ğŸ’¬ **Interactive CLI** | `uv run python main.py` |\n",
                "| ğŸ§ª **Run evaluation** | `uv run python eval/evaluate.py --provider gemini` |\n",
                "| ğŸ  **Local eval** | `uv run python eval/evaluate.py --local --model mistral` |\n",
                "| ğŸ“– **Quick eval** | `uv run python eval/evaluate.py --quick --local` |\n",
                "\n",
                "### Architecture\n",
                "\n",
                "```\n",
                "User Message\n",
                "    â”‚\n",
                "    â–¼\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚    Context Manager      â”‚ â† checks if context needs flushing\n",
                "â”‚    (token counting)     â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "         â”‚ if >70% full\n",
                "         â–¼\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚    Memory Distiller     â”‚ â† LLM extracts memories from conversation\n",
                "â”‚    (Groq/Gemini/Ollama) â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "         â”‚\n",
                "         â–¼\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚    Memory Store         â”‚ â† SQLite + sqlite-vec + FTS5\n",
                "â”‚    (persist & search)   â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "         â”‚\n",
                "         â–¼\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚    Memory Retriever     â”‚ â† hybrid vector + keyword search\n",
                "â”‚    (RRF fusion)         â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "         â”‚\n",
                "         â–¼\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚    System Prompt        â”‚ â† memories injected into context\n",
                "â”‚    + LLM Response       â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cleanup (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment to delete the demo database:\n",
                "# os.remove(demo_db)\n",
                "# print(f'âœ“ Removed {demo_db}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## NOTE: To check the actual metrics, check out results.ipynb"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
