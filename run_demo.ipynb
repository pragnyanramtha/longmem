{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ§  Atlas â€” Interactive Demo\n",
                "\n",
                "Welcome! This notebook walks you through the Atlas long-form memory system step by step.\n",
                "\n",
                "**What you'll learn:**\n",
                "1. How the agent extracts memories from conversation\n",
                "2. How memories are stored and retrieved\n",
                "3. How to test memory recall\n",
                "4. How to use different providers (Ollama, Gemini, Groq)\n",
                "\n",
                "> ğŸ“Š For full benchmarks and evaluation results, see **[results.ipynb](results.ipynb)**\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup\n",
                "\n",
                "First, install dependencies and load the environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ“ Dependencies loaded\n",
                        "  Project root: /home/pik/dev/atlas\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "import json\n",
                "from pathlib import Path\n",
                "\n",
                "# Add project root to path\n",
                "project_root = Path.cwd()\n",
                "if str(project_root) not in sys.path:\n",
                "    sys.path.insert(0, str(project_root))\n",
                "\n",
                "from src.agent import LongMemAgent\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "print('âœ“ Dependencies loaded')\n",
                "print(f'  Project root: {project_root}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Choose Your Provider\n",
                "\n",
                "Atlas supports multiple LLM backends. Pick one:\n",
                "\n",
                "| Provider | Model | API Key Needed | Notes |\n",
                "|----------|-------|:--------------:|-------|\n",
                "| `ollama` | `mistral` | No | Local, fast, free. Run `ollama serve` first |\n",
                "| `gemini` | `gemma-3-27b-it` | `GEMINI_API_KEY` | Free tier, 30 req/min |\n",
                "| `groq` | `llama-3.1-8b-instant` | `GROQ_API_KEY` | Very fast, rate limited |\n",
                "\n",
                "Edit the cell below to change providers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ—‘ï¸  Cleaned previous demo_interactive.db\n",
                        "\n",
                        "âœ“ Agent initialized\n",
                        "  Provider: groq\n",
                        "  Model:    moonshotai/kimi-k2-instruct-0905\n",
                        "  DB:       demo_interactive.db\n"
                    ]
                }
            ],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# ğŸ”§ CONFIGURE YOUR PROVIDER HERE\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\n",
                "PROVIDER = 'groq'                 # 'ollama', 'gemini', or 'groq'\n",
                "# MODEL    = 'mistral'                # model name for your provider\n",
                "# MODEL  = 'gemma-3-27b-it'         # uncomment for Gemini\n",
                "MODEL  = 'moonshotai/kimi-k2-instruct-0905'   # uncomment for Groq\n",
                "\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\n",
                "# Clean up any previous demo database\n",
                "demo_db = 'demo_interactive.db'\n",
                "if os.path.exists(demo_db):\n",
                "    os.remove(demo_db)\n",
                "    print(f'ğŸ—‘ï¸  Cleaned previous {demo_db}')\n",
                "\n",
                "# Initialize agent\n",
                "agent = LongMemAgent(\n",
                "    provider=PROVIDER,\n",
                "    model=MODEL,\n",
                "    db_path=demo_db,\n",
                "    context_limit=4096,\n",
                "    flush_threshold=0.70\n",
                ")\n",
                "\n",
                "print(f'\\nâœ“ Agent initialized')\n",
                "print(f'  Provider: {agent.provider}')\n",
                "print(f'  Model:    {agent.model}')\n",
                "print(f'  DB:       {demo_db}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Chat Helper\n",
                "\n",
                "A nice helper to display conversations with memory metadata."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ“ Chat helper ready. Use chat(\"your message\") below!\n"
                    ]
                }
            ],
            "source": [
                "from IPython.display import display, Markdown, HTML\n",
                "\n",
                "def chat(message: str, show_memories=True):\n",
                "    \"\"\"Send a message and display the response with memory info.\"\"\"\n",
                "    print(f'\\n You: {message}')\n",
                "    \n",
                "    response = agent.chat(message)\n",
                "    \n",
                "    print(f'Atlas: {response[\"response\"]}')\n",
                "    print(f'\\n   â”Œâ”€ Turn {response[\"turn_id\"]} â”‚ '\n",
                "          f'Context: {response[\"context_utilization\"]} â”‚ '\n",
                "          f'Memories: {response[\"total_memories\"]} â”‚ '\n",
                "          f'Flush: {\"yes\" if response[\"flush_triggered\"] else \"no\"}')\n",
                "    \n",
                "    if show_memories and response['active_memories']:\n",
                "        print(f'   â”‚ ğŸ§  Retrieved {len(response[\"active_memories\"])} memories:')\n",
                "        for mem in response['active_memories']:\n",
                "            print(f'   â”‚   â€¢ {mem[\"content\"]} '\n",
                "                  f'(from turn {mem[\"origin_turn\"]}, conf: {mem[\"confidence\"]:.2f})')\n",
                "    print('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')\n",
                "    \n",
                "    \n",
                "    return response\n",
                "\n",
                "print('âœ“ Chat helper ready. Use chat(\"your message\") below!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Plant Some Memories\n",
                "\n",
                "Let's tell the agent some facts about ourselves. These will be extracted as memories."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ‘¤ You: Hi! My name is Jordan and I work as a data scientist in Seattle.\n",
                        "ğŸ¤– Atlas: Nice to meet you, Jordanâ€”Seattleâ€™s a great hub for data work. Howâ€™s the scene treating you these days?\n",
                        "\n",
                        "   â”Œâ”€ Turn 1 â”‚ Context: 3% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                        "\n",
                        "ğŸ‘¤ You: I'm allergic to peanuts and I follow a vegetarian diet.\n",
                        "ğŸ¤– Atlas: Got itâ€”peanuts off the table and vegetarian plates only. Anything in particular youâ€™d like help with right now?\n",
                        "\n",
                        "   â”Œâ”€ Turn 2 â”‚ Context: 5% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                        "\n",
                        "ğŸ‘¤ You: My favorite programming language is Python. I also use R for statistics.\n",
                        "ğŸ¤– Atlas: Solid comboâ€”Python for the heavy lifting and R when you need the statistical muscle.\n",
                        "\n",
                        "   â”Œâ”€ Turn 3 â”‚ Context: 5% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                        "\n",
                        "ğŸ‘¤ You: I have a daughter named Maya, she is 5 years old.\n",
                        "ğŸ¤– Atlas: Five is such a fun ageâ€”lots of curiosity and energy. Howâ€™s Maya doing?\n",
                        "\n",
                        "   â”Œâ”€ Turn 4 â”‚ Context: 6% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'Five is such a fun ageâ€”lots of curiosity and energy. Howâ€™s Maya doing?',\n",
                            " 'turn_id': 4,\n",
                            " 'context_utilization': '6%',\n",
                            " 'context_tokens': 264,\n",
                            " 'retrieval_ms': 0.0,\n",
                            " 'total_ms': 531.0,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 0,\n",
                            " 'active_memories': [],\n",
                            " 'total_memories': 0}"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "chat('Hi! My name is Jordan and I work as a data scientist in Seattle.')\n",
                "chat(\"I'm allergic to peanuts and I follow a vegetarian diet.\")\n",
                "chat('My favorite programming language is Python. I also use R for statistics.')\n",
                "chat('I have a daughter named Maya, she is 5 years old.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Trigger Memory Distillation\n",
                "\n",
                "The agent normally distills memories when context hits 70% capacity.\n",
                "We can also trigger it manually to extract memories right now."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âš¡ Triggering memory distillation...\n",
                        "\n",
                        "[distiller] Skipping malformed memory item: DistilledMemory.__init__() got an unexpected keyword argument 'reasoning'\n",
                        "[distiller] Skipping malformed memory item: DistilledMemory.__init__() got an unexpected keyword argument 'reasoning'\n",
                        "[distiller] Skipping malformed memory item: DistilledMemory.__init__() got an unexpected keyword argument 'reasoning'\n",
                        "[distiller] Skipping malformed memory item: DistilledMemory.__init__() got an unexpected keyword argument 'reasoning'\n",
                        "[distiller] Skipping malformed memory item: DistilledMemory.__init__() got an unexpected keyword argument 'reasoning'\n",
                        "[distiller] Skipping malformed memory item: DistilledMemory.__init__() got an unexpected keyword argument 'reasoning'\n",
                        "[distiller] Skipping malformed memory item: DistilledMemory.__init__() got an unexpected keyword argument 'reasoning'\n",
                        "[distiller] Skipping malformed memory item: DistilledMemory.__init__() got an unexpected keyword argument 'reasoning'\n",
                        "âœ“ Distillation complete. 0 memories extracted.\n",
                        "  Memories added: 0\n",
                        "  Total memories: 0\n"
                    ]
                }
            ],
            "source": [
                "print('âš¡ Triggering memory distillation...\\n')\n",
                "\n",
                "result = agent.manual_distill()\n",
                "\n",
                "print(f'âœ“ {result[\"message\"]}')\n",
                "print(f'  Memories added: {result[\"memories_added\"]}')\n",
                "print(f'  Total memories: {result[\"total_memories\"]}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Inspect Stored Memories\n",
                "\n",
                "Let's see what the distiller extracted."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "No memories stored yet. Run distillation first.\n"
                    ]
                }
            ],
            "source": [
                "memories = agent.get_all_memories()\n",
                "\n",
                "if memories:\n",
                "    print(f'ğŸ“¦ Stored Memories ({len(memories)} total):\\n')\n",
                "    for m in memories:\n",
                "        print(f\"  [{m['type']:>12}] {m['key']}: {m['value']}\")\n",
                "        print(f\"               confidence: {m['confidence']:.2f}, from turn {m['source_turn']}\")\n",
                "else:\n",
                "    print('No memories stored yet. Run distillation first.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Test Memory Recall\n",
                "\n",
                "Now the key test â€” does the agent remember what we told it?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ‘¤ You: What's my name?\n",
                        "ğŸ¤– Atlas: You havenâ€™t told me your name yetâ€”what would you like me to call you?\n",
                        "\n",
                        "   â”Œâ”€ Turn 5 â”‚ Context: 5% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'You havenâ€™t told me your name yetâ€”what would you like me to call you?',\n",
                            " 'turn_id': 5,\n",
                            " 'context_utilization': '5%',\n",
                            " 'context_tokens': 202,\n",
                            " 'retrieval_ms': 0.1,\n",
                            " 'total_ms': 722.0,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 1,\n",
                            " 'active_memories': [],\n",
                            " 'total_memories': 0}"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "chat(\"What's my name?\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ‘¤ You: Suggest a dinner recipe for me.\n",
                        "ğŸ¤– Atlas: Quick one-pan lemon-garlic chicken thighs with roasted veggies: toss bone-in thighs, baby potatoes, and broccoli with olive oil, lemon zest, garlic, salt, and pepper; 25 min at 425 Â°F. While it roasts you can help Maya set the tableâ€”sheâ€™ll like the bright lemon smell.\n",
                        "\n",
                        "   â”Œâ”€ Turn 6 â”‚ Context: 7% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'Quick one-pan lemon-garlic chicken thighs with roasted veggies: toss bone-in thighs, baby potatoes, and broccoli with olive oil, lemon zest, garlic, salt, and pepper; 25 min at 425 Â°F. While it roasts you can help Maya set the tableâ€”sheâ€™ll like the bright lemon smell.',\n",
                            " 'turn_id': 6,\n",
                            " 'context_utilization': '7%',\n",
                            " 'context_tokens': 285,\n",
                            " 'retrieval_ms': 0.3,\n",
                            " 'total_ms': 800.5,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 1,\n",
                            " 'active_memories': [],\n",
                            " 'total_memories': 0}"
                        ]
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "chat('Suggest a dinner recipe for me.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ‘¤ You: What should I get my kid for her birthday?\n",
                        "ğŸ¤– Atlas: Five-year-olds love open-ended play that lets them build or pretend. A few ideas that usually land:\n",
                        "\n",
                        "- Magnetic tile set â€“ bright colors, easy for small hands, grows with her\n",
                        "- Realistic animal figurines (Schleich or similar) â€“ sparks storytelling and pairs with blocks she already has\n",
                        "- Kid-size gardening kit â€“ trowel, gloves, and a couple of seed packets; you can plant together on the weekend\n",
                        "- Story-game board book like â€œPress Hereâ€ or â€œThe Book with No Picturesâ€ â€“ interactive read-alouds she can â€œcontrolâ€\n",
                        "- Dress-up trunk add-on: a reversible cape, a few costume masks, and a pair of â€œmagicâ€ glovesâ€”instant superhero/royalty switch-ups\n",
                        "\n",
                        "Pick whichever matches her current obsession (animals, building, or make-believe) and youâ€™ll nail it.\n",
                        "\n",
                        "   â”Œâ”€ Turn 7 â”‚ Context: 12% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'Five-year-olds love open-ended play that lets them build or pretend. A few ideas that usually land:\\n\\n- Magnetic tile set â€“ bright colors, easy for small hands, grows with her\\n- Realistic animal figurines (Schleich or similar) â€“ sparks storytelling and pairs with blocks she already has\\n- Kid-size gardening kit â€“ trowel, gloves, and a couple of seed packets; you can plant together on the weekend\\n- Story-game board book like â€œPress Hereâ€ or â€œThe Book with No Picturesâ€ â€“ interactive read-alouds she can â€œcontrolâ€\\n- Dress-up trunk add-on: a reversible cape, a few costume masks, and a pair of â€œmagicâ€ glovesâ€”instant superhero/royalty switch-ups\\n\\nPick whichever matches her current obsession (animals, building, or make-believe) and youâ€™ll nail it.',\n",
                            " 'turn_id': 7,\n",
                            " 'context_utilization': '12%',\n",
                            " 'context_tokens': 475,\n",
                            " 'retrieval_ms': 0.4,\n",
                            " 'total_ms': 1487.3,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 1,\n",
                            " 'active_memories': [],\n",
                            " 'total_memories': 0}"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "chat('What should I get my kid for her birthday?')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ‘¤ You: Tell me everything you remember about me.\n",
                        "ğŸ¤– Atlas: You code in Python and reach for R when you need statistical tools. You have a five-year-old daughter named Maya, and you like quick, practical dinner solutions that leave time to hang out with her.\n",
                        "\n",
                        "   â”Œâ”€ Turn 8 â”‚ Context: 13% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'You code in Python and reach for R when you need statistical tools. You have a five-year-old daughter named Maya, and you like quick, practical dinner solutions that leave time to hang out with her.',\n",
                            " 'turn_id': 8,\n",
                            " 'context_utilization': '13%',\n",
                            " 'context_tokens': 532,\n",
                            " 'retrieval_ms': 0.4,\n",
                            " 'total_ms': 828.2,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 1,\n",
                            " 'active_memories': [],\n",
                            " 'total_memories': 0}"
                        ]
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "chat('Tell me everything you remember about me.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Try It Yourself!\n",
                "\n",
                "Use the cell below to have your own conversation with the agent.\n",
                "Each message is processed through the full memory pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ‘¤ You: What do I do for work?\n",
                        "ğŸ¤– Atlas: You havenâ€™t mentioned your job yetâ€”what field are you in?\n",
                        "\n",
                        "   â”Œâ”€ Turn 9 â”‚ Context: 14% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'You havenâ€™t mentioned your job yetâ€”what field are you in?',\n",
                            " 'turn_id': 9,\n",
                            " 'context_utilization': '14%',\n",
                            " 'context_tokens': 561,\n",
                            " 'retrieval_ms': 0.4,\n",
                            " 'total_ms': 756.2,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 1,\n",
                            " 'active_memories': [],\n",
                            " 'total_memories': 0}"
                        ]
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Type your message here:\n",
                "chat('What do I do for work?')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ‘¤ You: Your message here\n",
                        "ğŸ¤– Atlas: Got itâ€”thanks for the update.\n",
                        "\n",
                        "   â”Œâ”€ Turn 10 â”‚ Context: 14% â”‚ Memories: 0 â”‚ Flush: no\n",
                        "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'response': 'Got itâ€”thanks for the update.',\n",
                            " 'turn_id': 10,\n",
                            " 'context_utilization': '14%',\n",
                            " 'context_tokens': 580,\n",
                            " 'retrieval_ms': 0.5,\n",
                            " 'total_ms': 541.3,\n",
                            " 'flush_triggered': False,\n",
                            " 'total_flushes': 1,\n",
                            " 'active_memories': [],\n",
                            " 'total_memories': 0}"
                        ]
                    },
                    "execution_count": 30,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Try another:\n",
                "chat('Your message here')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Database Peek\n",
                "\n",
                "Under the hood, memories are stored in SQLite with vector embeddings + full-text search indexes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ“‹ Database: demo_interactive.db\n",
                        "   Active memories: 0\n",
                        "   Total turns: 10\n",
                        "   Memory types:\n"
                    ]
                }
            ],
            "source": [
                "import sqlite3\n",
                "\n",
                "conn = sqlite3.connect(demo_db)\n",
                "cursor = conn.cursor()\n",
                "\n",
                "cursor.execute('SELECT COUNT(*) FROM memories WHERE is_active = 1')\n",
                "active = cursor.fetchone()[0]\n",
                "\n",
                "cursor.execute('SELECT COUNT(*) FROM turns')\n",
                "turns = cursor.fetchone()[0]\n",
                "\n",
                "cursor.execute('''\n",
                "    SELECT type, COUNT(*) as count \n",
                "    FROM memories WHERE is_active = 1 \n",
                "    GROUP BY type\n",
                "''')\n",
                "types = cursor.fetchall()\n",
                "\n",
                "print(f'ğŸ“‹ Database: {demo_db}')\n",
                "print(f'   Active memories: {active}')\n",
                "print(f'   Total turns: {turns}')\n",
                "print(f'   Memory types:')\n",
                "for type_name, count in types:\n",
                "    print(f'     {type_name}: {count}')\n",
                "\n",
                "conn.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Next Steps\n",
                "\n",
                "| What | How |\n",
                "|:-----|:----|\n",
                "| ğŸ“Š **See benchmarks** | Open [results.ipynb](results.ipynb) |\n",
                "| ğŸ’¬ **Interactive CLI** | `uv run python main.py` |\n",
                "| ğŸ§ª **Run evaluation** | `uv run python eval/evaluate.py --provider gemini` |\n",
                "| ğŸ  **Local eval** | `uv run python eval/evaluate.py --local --model mistral` |\n",
                "| ğŸ“– **Quick eval** | `uv run python eval/evaluate.py --quick --local` |\n",
                "\n",
                "### Architecture\n",
                "\n",
                "```\n",
                "User Message\n",
                "    â”‚\n",
                "    â–¼\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚    Context Manager      â”‚ â† checks if context needs flushing\n",
                "â”‚    (token counting)     â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "         â”‚ if >70% full\n",
                "         â–¼\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚    Memory Distiller     â”‚ â† LLM extracts memories from conversation\n",
                "â”‚    (Groq/Gemini/Ollama) â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "         â”‚\n",
                "         â–¼\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚    Memory Store         â”‚ â† SQLite + sqlite-vec + FTS5\n",
                "â”‚    (persist & search)   â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "         â”‚\n",
                "         â–¼\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚    Memory Retriever     â”‚ â† hybrid vector + keyword search\n",
                "â”‚    (RRF fusion)         â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "         â”‚\n",
                "         â–¼\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚    System Prompt        â”‚ â† memories injected into context\n",
                "â”‚    + LLM Response       â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cleanup (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment to delete the demo database:\n",
                "# os.remove(demo_db)\n",
                "# print(f'âœ“ Removed {demo_db}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## NOTE: To check the actual metrics, check out results.ipynb"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
