# LLM API Configuration
# Groq (default, recommended for fast inference)
GROQ_API_KEY=gsk_your_api_key_here

# OpenAI (alternative)
# OPENAI_API_KEY=sk-your_api_key_here

# Local Models (Ollama)
# OLLAMA_BASE_URL=http://localhost:11434/v1
# OLLAMA_MODEL=mistral

# Database Configuration (optional, defaults to memory.db)
# DB_PATH=custom_memory.db
