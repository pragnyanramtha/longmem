# LLM API Configuration
# Groq (default, recommended for fast inference)
GROQ_API_KEY=gsk_your_api_key_here

# OpenAI (alternative)
# OPENAI_API_KEY=sk-your_api_key_here

# Local Models (Ollama)
# OLLAMA_BASE_URL=http://localhost:11434/v1
# OLLAMA_MODEL=mistral

# Database Configuration (optional, defaults to memory.db)
# DB_PATH=custom_memory.db

# Gemini (Google AI - free tier: 30 req/min)
# Model: gemma-3-27b-it
# GEMINI_API_KEY=your_gemini_api_key_here
